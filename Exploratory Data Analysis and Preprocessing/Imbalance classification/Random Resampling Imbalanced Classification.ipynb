{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressed-snake",
   "metadata": {},
   "source": [
    "# Random Resampling Imbalanced Classification\n",
    "\n",
    "Resampling involves creating a new transformed version of the training dataset in which the selected examples have a different class distribution.\n",
    "\n",
    "This is a simple and effective strategy for imbalanced classification problems.\n",
    "\n",
    "> Applying re-sampling strategies to obtain a more balanced data distribution is an effective solution to the imbalance problem.\n",
    "\n",
    "The simplest strategy is to choose examples for the transformed dataset randomly, called random resampling.\n",
    "\n",
    "There are two main approaches to random resampling for imbalanced classification; they are oversampling and undersampling.\n",
    "\n",
    "- **Random Oversampling:** Randomly duplicate examples in the minority class.\n",
    "- **Random Undersampling:** Randomly delete examples in the majority class.\n",
    "\n",
    "Random oversampling involves randomly selecting examples from the minority class, with replacement, and adding them to the training dataset. Random undersampling involves randomly selecting examples from the majority class and deleting them from the training dataset.\n",
    "\n",
    "> In the random under-sampling, the majority class instances are discarded at random until a more balanced distribution is reached.\n",
    "\n",
    "Both approaches can be repeated until the desired class distribution is achieved in the training dataset, such as an equal split across the classes.\n",
    "\n",
    "They are referred to as “naive resampling” methods because they assume nothing about the data and no heuristics are used. This makes them simple to implement and fast to execute, which is desirable for very large and complex datasets.\n",
    "\n",
    "Both techniques can be used for two-class (binary) classification problems and multi-class classification problems with one or more majority or minority classes.\n",
    "\n",
    "Importantly, the change to the class distribution is only applied to the training dataset. The intent is to influence the fit of the models. The resampling is not applied to the test or holdout dataset used to evaluate the performance of a model.\n",
    "\n",
    "Generally, these naive methods can be effective, although that depends on the specifics of the dataset and models involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-example",
   "metadata": {},
   "source": [
    "## 1. Random Oversampling Imbalanced Datasets\n",
    "\n",
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset.\n",
    "\n",
    "Examples from the training dataset are selected randomly with replacement. This means that examples from the minority class can be chosen and added to the new “more balanced” training dataset multiple times; they are selected from the original training dataset, added to the new training dataset, and then returned or “replaced” in the original dataset, allowing them to be selected again.\n",
    "\n",
    "This technique can be effective for those machine learning algorithms that are affected by a skewed distribution and where multiple duplicate examples for a given class can influence the fit of the model. This might include algorithms that iteratively learn coefficients, like artificial neural networks that use stochastic gradient descent. It can also affect models that seek good splits of the data, such as support vector machines and decision trees.\n",
    "\n",
    "It might be useful to tune the target class distribution. In some cases, seeking a balanced distribution for a severely imbalanced dataset can cause affected algorithms to overfit the minority class, leading to increased generalization error. The effect can be better performance on the training dataset, but worse performance on the holdout or test dataset.\n",
    "\n",
    "> … the random oversampling may increase the likelihood of occurring overfitting, since it makes exact copies of the minority class examples. In this way, a symbolic classifier, for instance, might construct rules that are apparently accurate, but actually cover one replicated example.\n",
    "\n",
    "As such, to gain insight into the impact of the method, it is a good idea to monitor the performance on both train and test datasets after oversampling and compare the results to the same algorithm on the original dataset.\n",
    "\n",
    "The increase in the number of examples for the minority class, especially if the class skew was severe, can also result in a marked increase in the computational cost when fitting the model, especially considering the model is seeing the same examples in the training dataset again and again.\n",
    "\n",
    "> … in random over-sampling, a random set of copies of minority class examples is added to the data. This may increase the likelihood of overfitting, specially for higher over-sampling rates. Moreover, it may decrease the classifier performance and increase the computational effort.\n",
    "\n",
    "Random oversampling can be implemented using the `RandomOverSampler` class.\n",
    "\n",
    "The class can be defined and takes a sampling_strategy argument that can be set to “minority” to automatically balance the minority class with majority class or classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-exclusion",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "determined-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-brisbane",
   "metadata": {},
   "source": [
    "### define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peaceful-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-notice",
   "metadata": {},
   "source": [
    "### summarize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "departmental-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-shift",
   "metadata": {},
   "source": [
    "### define oversampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "working-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-groove",
   "metadata": {},
   "source": [
    "### fit and apply the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "standing-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_over = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-preserve",
   "metadata": {},
   "source": [
    "### summarize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "connected-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 9900})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-bride",
   "metadata": {},
   "source": [
    "Running the example first creates the dataset, then summarizes the class distribution. We can see that there are nearly 10K examples in the majority class and 100 examples in the minority class.\n",
    "\n",
    "Then the random oversample transform is defined to balance the minority class, then fit and applied to the dataset. The class distribution for the transformed dataset is reported showing that now the minority class has the same number of examples as the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-importance",
   "metadata": {},
   "source": [
    "### Using Pipeline\n",
    "\n",
    "This transform can be used as part of a Pipeline to ensure that it is only applied to the training dataset as part of each split in a k-fold cross validation.\n",
    "\n",
    "A traditional scikit-learn Pipeline cannot be used; instead, a Pipeline from the imbalanced-learn library can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-jesus",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "viral-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-princess",
   "metadata": {},
   "source": [
    "### define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "absent-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-attendance",
   "metadata": {},
   "source": [
    "### define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baking-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('over', RandomOverSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-swaziland",
   "metadata": {},
   "source": [
    "### evaluate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "muslim-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.990\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-hebrew",
   "metadata": {},
   "source": [
    "## 2. Random Undersampling Imbalanced Datasets\n",
    "\n",
    "Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset.\n",
    "\n",
    "This has the effect of reducing the number of examples in the majority class in the transformed version of the training dataset. This process can be repeated until the desired class distribution is achieved, such as an equal number of examples for each class.\n",
    "\n",
    "This approach may be more suitable for those datasets where there is a class imbalance although a sufficient number of examples in the minority class, such a useful model can be fit.\n",
    "\n",
    "A limitation of undersampling is that examples from the majority class are deleted that may be useful, important, or perhaps critical to fitting a robust decision boundary. Given that examples are deleted randomly, there is no way to detect or preserve “good” or more information-rich examples from the majority class.\n",
    "\n",
    "> … in random under-sampling (potentially), vast quantities of data are discarded. […] This can be highly problematic, as the loss of such data can make the decision boundary between minority and majority instances harder to learn, resulting in a loss in classification performance.\n",
    "\n",
    "The class can be used just like the `RandomOverSampler` class in the previous section, except the strategies impact the majority class instead of the minority class. For example, setting the sampling_strategy argument to “majority” will undersample the majority class determined by the class with the largest number of examples.\n",
    "\n",
    "For example, a dataset with 1,000 examples in the majority class and 100 examples in the minority class will be undersampled such that both classes would have 100 examples in the transformed training dataset.\n",
    "\n",
    "We can also set the sampling_strategy argument to a floating point value which will be a percentage relative to the minority class, specifically the number of examples in the minority class divided by the number of examples in the majority class. For example, if we set sampling_strategy to 0.5 in an imbalanced data dataset with 1,000 examples in the majority class and 100 examples in the minority class, then there would be 200 examples for the majority class in the transformed dataset (or 100/200 = 0.5).\n",
    "\n",
    "This might be preferred to ensure that the resulting dataset is both large enough to fit a reasonable model, and that not too much useful information from the majority class is discarded.\n",
    "\n",
    "> In random under-sampling, one might attempt to create a balanced class distribution by selecting 90 majority class instances at random to be removed. The resulting dataset will then consist of 20 instances: 10 (randomly remaining) majority class instances and (the original) 10 minority class instances.\n",
    "\n",
    "The transform can then be fit and applied to a dataset in one step by calling the fit_resample() function and passing the untransformed dataset as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-government",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "physical-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-lloyd",
   "metadata": {},
   "source": [
    "### define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "drawn-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-bearing",
   "metadata": {},
   "source": [
    "### summarize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "muslim-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-lender",
   "metadata": {},
   "source": [
    "### define undersample strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "unable-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-mission",
   "metadata": {},
   "source": [
    "### fit and apply the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "absolute-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_over = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-removal",
   "metadata": {},
   "source": [
    "### summarize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "different-recycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 100, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-terrorist",
   "metadata": {},
   "source": [
    "### Using Pipeline\n",
    "\n",
    "This undersampling transform can also be used in a Pipeline.\n",
    "\n",
    "This allows the transform to be applied to the training dataset only using evaluation schemes such as k-fold cross-validation, avoiding any *data leakage* in the evaluation of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-chest",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "modular-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-exclusion",
   "metadata": {},
   "source": [
    "#### define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aware-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('under', RandomUnderSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-jacob",
   "metadata": {},
   "source": [
    "#### evaluate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "necessary-laptop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.869\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-register",
   "metadata": {},
   "source": [
    "## 3. Combining Random Oversampling and Undersampling\n",
    "\n",
    "Interesting results may be achieved by combining both random oversampling and undersampling.\n",
    "\n",
    "For example, a modest amount of oversampling can be applied to the minority class to improve the bias towards these examples, whilst also applying a modest amount of undersampling to the majority class to reduce the bias on that class.\n",
    "\n",
    "This can result in improved overall performance compared to performing one or the other techniques in isolation.\n",
    "\n",
    "For example, if we had a dataset with a 1:100 class distribution, we might first apply oversampling to increase the ratio to 1:10 by duplicating examples from the minority class, then apply undersampling to further improve the ratio to 1:2 by deleting examples from the majority class.\n",
    "\n",
    "This could be implemented using imbalanced-learn by using a RandomOverSampler with sampling_strategy set to 0.1 (10%), then using a RandomUnderSampler with a sampling_strategy set to 0.5 (50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fitted-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n",
      "Counter({0: 9900, 1: 990})\n",
      "Counter({0: 1980, 1: 990})\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "# define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "# fit and apply the transform\n",
    "X, y = over.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "# define undersampling strategy\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# fit and apply the transform\n",
    "X, y = under.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-legislation",
   "metadata": {},
   "source": [
    "Running the example first creates the synthetic dataset and summarizes the class distribution, showing an approximate 1:100 class distribution.\n",
    "\n",
    "Then oversampling is applied, increasing the distribution from about 1:100 to about 1:10. Finally, undersampling is applied, further improving the class distribution from 1:10 to about 1:2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-wallet",
   "metadata": {},
   "source": [
    "### Using Pipeline\n",
    "\n",
    "We might also want to apply this same hybrid approach when evaluating a model using k-fold cross-validation.\n",
    "\n",
    "This can be achieved by using a Pipeline with a sequence of transforms and ending with the model that is being evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "developed-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "closing-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.980\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# define pipeline\n",
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under), ('m', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-webmaster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
